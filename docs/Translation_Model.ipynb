{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c868a4d3-90f5-401b-bbf1-67d27238f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import jieba\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1281c57-7449-4347-a5aa-1072d2e88362",
   "metadata": {},
   "source": [
    "Preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af05159e-07a8-46c7-84d8-6ee3315919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # replace '\\n' with ' '\n",
    "        data = pd.Series(f.readlines())\n",
    "        data = data.str.replace('\\n', ' ')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b1e446-4061-4274-bb52-049fdbedf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ZH = load_data('chinese.zh')\n",
    "data_EN = load_data('english.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47abd0a9-1bec-489b-8336-76e397c1e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ZH = data_ZH[:10000]\n",
    "data_EN = data_EN[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a49339-6045-467a-921c-8cab930caf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/s8/pbv_qcy127g2gt_nwhfbrnxr0000gn/T/jieba.cache\n",
      "Loading model cost 0.339 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                    1929 å¹´ è¿˜æ˜¯ 1989 å¹´ ?  \n",
       "1       å·´é» - éšç€ ç»æµå±æœº ä¸æ–­ åŠ æ·± å’Œ è”“å»¶ ï¼Œ æ•´ä¸ª ä¸–ç•Œ ä¸€ç›´ åœ¨ å¯»æ‰¾ å†å² ä¸Š çš„...\n",
       "2       ä¸€ å¼€å§‹ ï¼Œ å¾ˆå¤š äºº æŠŠ è¿™æ¬¡ å±æœº æ¯”ä½œ 1982 å¹´ æˆ– 1973 å¹´ æ‰€ å‘ç”Ÿ çš„ ...\n",
       "3       å¦‚ä»Š äººä»¬ çš„ å¿ƒæƒ… å´æ˜¯ æ²‰é‡ å¤š äº† ï¼Œ è®¸å¤š äºº å¼€å§‹ æŠŠ è¿™æ¬¡ å±æœº ä¸ 1929 ...\n",
       "4       ç›®å‰ çš„ è¶‹åŠ¿ æ˜¯ ï¼Œ è¦ä¹ˆ æ˜¯ è¿‡åº¦ çš„ å…‹åˆ¶ ï¼ˆ æ¬§æ´² ï¼‰ ï¼Œ è¦ä¹ˆ æ˜¯ åŠªåŠ› çš„ æ‰©å±•...\n",
       "                              ...                        \n",
       "9995    æ ¹æ® åƒ çº¦ç¿° Â· éº¦å‡¯æ© è¿™æ · çš„ äºº çš„ è§‚ç‚¹ ï¼Œ æœ€ æ ¹æœ¬ çš„ åŸå›  æ˜¯ åå°”è¡— çš„ ...\n",
       "9996    è™½ç„¶ æˆ‘ ä¸ å¦è®¤ è¿™æ · çš„ åŸºç¡€ åŠ¨åŠ› çš„ å­˜åœ¨ ï¼Œ ä½†æ˜¯ ï¼Œ æˆ‘ è¿˜æ˜¯ åšæŒ è®¤ä¸º è¿™åœº...\n",
       "9997                              åœ¨ ç¾å›½ ï¼Œ æœ‰ ä¸¤ä¸ª å…³é”® çš„ å†³å®š ã€‚  \n",
       "9998    ç¬¬ä¸€ä¸ª æ˜¯ åœ¨ 20 ä¸–çºª 70 å¹´ä»£ è§£é™¤ äº† å¯¹ æ”¯ä»˜ ç»™ è‚¡ç¥¨ ç»çºªäºº çš„ ä½£é‡‘ çš„ ...\n",
       "9999    ç¬¬äºŒä¸ª æ˜¯ åœ¨ 20 ä¸–çºª 90 å¹´ä»£ åºŸæ­¢ äº† ã€Š æ ¼æ‹‰æ–¯ - æ–¯è’‚æ ¼ å°”æ³• ã€‹ å¯¹ å•†ä¸š...\n",
       "Length: 10000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut_ZH(data):\n",
    "    data_cut = data.apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "    return data_cut\n",
    "\n",
    "data_ZH = cut_ZH(data_ZH)\n",
    "data_ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ab7b9c-f817-4b83-96ed-8256275737a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZH = data_ZH.to_frame()\n",
    "df_EN = data_EN.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2844f-0a1a-4098-9676-343d6c0473af",
   "metadata": {},
   "source": [
    "Constants and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e6c66e-c3a7-4979-84b0-f0bf28a631bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH = 'en'\n",
    "CHINESE = 'zh'\n",
    "PREFIX = \"\"\n",
    "MAX_INPUT_LENGTH = 128\n",
    "MAX_TARGET_LENGTH = 128\n",
    "INPUT_IDS = \"input_ids\"\n",
    "LABELS = \"labels\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad23d28-5d74-4a1a-b68c-486571dd0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds: list, labels: list) -> tuple:\n",
    "    \"\"\"Performs post processing on the prediction text and labels\"\"\"\n",
    "\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df749b8-468a-4724-ac47-9d1c7d656357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_model_fine_tuning(source_lang: list, target_lang: list) -> list:\n",
    "    \"\"\"Takes the input data lists and converts into translation list of dicts\"\"\"\n",
    "\n",
    "    data_dict = dict()\n",
    "    data_dict['translation'] = []\n",
    "\n",
    "    for sr_text, tr_text in zip(source_lang, target_lang):\n",
    "        temp_dict = dict()\n",
    "        temp_dict[CHINESE] = sr_text\n",
    "        temp_dict[ENGLISH] = tr_text\n",
    "\n",
    "        data_dict['translation'].append(temp_dict)\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6312e1d7-8a87-4788-8714-bc4d37a034e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_ready_dataset(dataset: list, source: str, target: str,\n",
    "                                 model_checkpoint: str,\n",
    "                                 tokenizer: AutoTokenizer):\n",
    "    \"\"\"Makes the data training ready for the model\"\"\"\n",
    "\n",
    "    preped_data = []\n",
    "\n",
    "    for row in dataset:\n",
    "        inputs = (PREFIX + row[source][0])\n",
    "        targets = (row[target][0])\n",
    "\n",
    "        model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH,\n",
    "                                 truncation=True, padding=True)\n",
    "\n",
    "        model_inputs['translation'] = row\n",
    "\n",
    "        # setup the tokenizer for targets\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(targets, max_length=MAX_INPUT_LENGTH,\n",
    "                                 truncation=True, padding=True)\n",
    "            model_inputs[LABELS] = labels[INPUT_IDS]\n",
    "\n",
    "        preped_data.append(model_inputs)\n",
    "\n",
    "    return preped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b2c83b-7c72-4ee4-93fb-428f24f63038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: tuple) -> dict:\n",
    "    \"\"\"computes bleu score and other performance metrics \"\"\"\n",
    "\n",
    "    metric = load_metric(\"sacrebleu\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {'bleu': result['score']}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "\n",
    "    result['gen_len'] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39d88b-f508-4998-b303-a0942c3fad24",
   "metadata": {},
   "source": [
    "Perform train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f73ec1-e18b-4e05-901e-4a1db57e441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ZH\n",
    "y = df_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee608bf-2397-4a43-8449-d2630d0a3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, shuffle = True, random_state = 100)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.20, shuffle = True, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1b77-6602-441f-a86b-8ddec9ff98c2",
   "metadata": {},
   "source": [
    "Load tokenizer. Using Hensinki-NLP Chinese to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a4d2d6-0520-40be-87ed-4991a3ae085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96a20c-1fe3-4d39-b915-9d8d03355635",
   "metadata": {},
   "source": [
    "Process dataset to make it suitable for model, including tokenisation and converting it into a Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b8faeb-f1d2-4877-a140-43ef29932d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training, validation, and test data\n",
    "training_data = prep_data_for_model_fine_tuning(X_train.values, y_train.values)\n",
    "validating_data = prep_data_for_model_fine_tuning(X_val.values, y_val.values)\n",
    "testing_data = prep_data_for_model_fine_tuning(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42def1fc-4c8a-47d1-8b44-d5c01e21bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate model-ready inputs for training, validation, and test\n",
    "train_data = generate_model_ready_dataset(dataset=training_data['translation'],\n",
    "                                          tokenizer=tokenizer,\n",
    "                                          source=CHINESE,\n",
    "                                          target=ENGLISH,\n",
    "                                          model_checkpoint='Helsinki-NLP/opus-mt-zh-en')\n",
    "validation_data = generate_model_ready_dataset(dataset=validating_data['translation'],\n",
    "                                               tokenizer=tokenizer,\n",
    "                                               source=CHINESE,\n",
    "                                               target=ENGLISH,\n",
    "                                               model_checkpoint='Helsinki-NLP/opus-mt-zh-en')\n",
    "test_data = generate_model_ready_dataset(dataset=testing_data['translation'],\n",
    "                                         tokenizer=tokenizer,\n",
    "                                         source=CHINESE,\n",
    "                                         target=ENGLISH,\n",
    "                                         model_checkpoint='Helsinki-NLP/opus-mt-zh-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5fd9c81-25dd-4482-9519-e8b143c695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame.from_records(train_data)\n",
    "validation_df = pd.DataFrame.from_records(validation_data)\n",
    "test_df = pd.DataFrame.from_records(test_data)\n",
    "\n",
    "# Convert DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde4853-3dd8-4494-adc5-40aca6b4618a",
   "metadata": {},
   "source": [
    "Prepare model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c01f78b-b5d9-492a-86da-01686ea788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and define training arguments\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "\n",
    "model_args = Seq2SeqTrainingArguments(\n",
    "    \"translation-pt-en-t5-finetuned-zh-to-en\",\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.02,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=7,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "# Create a data collator for sequence-to-sequence tasks\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2417a874-2387-447e-af7f-2716dfef80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d592108-4bf7-494f-98b6-6a154d1bd66b",
   "metadata": {},
   "source": [
    "Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "885dd25c-cb9c-4fba-b7a1-67dd5d4d385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    model_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f55a095d-9319-44b6-b879-dff26eae6da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3150' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 2:53:34, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.980045</td>\n",
       "      <td>21.802200</td>\n",
       "      <td>28.609400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.974800</td>\n",
       "      <td>2.019087</td>\n",
       "      <td>21.907500</td>\n",
       "      <td>29.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.218500</td>\n",
       "      <td>2.128166</td>\n",
       "      <td>22.105300</td>\n",
       "      <td>28.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>2.228374</td>\n",
       "      <td>22.449400</td>\n",
       "      <td>28.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>2.326017</td>\n",
       "      <td>22.683000</td>\n",
       "      <td>28.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>2.400083</td>\n",
       "      <td>22.699100</td>\n",
       "      <td>28.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>2.444219</td>\n",
       "      <td>22.971000</td>\n",
       "      <td>29.079400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/pbv_qcy127g2gt_nwhfbrnxr0000gn/T/ipykernel_93670/1112429398.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3150, training_loss=0.7614415686471122, metrics={'train_runtime': 10415.4698, 'train_samples_per_second': 4.839, 'train_steps_per_second': 0.302, 'total_flos': 1238519135600640.0, 'train_loss': 0.7614415686471122, 'epoch': 7.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d60520a5-0cae-4612-8aea-21ca03259dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"FineTunedTranslationModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f67c0-259a-4bce-bd50-b1eda39da67a",
   "metadata": {},
   "source": [
    "Test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0938c0ed-07ff-4f20-8f4c-58bb64352167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "828b7c6c-ac37-4541-9025-23a686c6ef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keejuan/Documents/ML/CNENTranslation/lib/python3.12/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a2f760d-46f3-4bd7-9c45-809a9f65dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Bleu Score:  22.7497\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Bleu Score: \", test_results.metrics[\"test_blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5b440-ac3b-45d2-bc61-db4599ba3475",
   "metadata": {},
   "source": [
    "Generate predicted sentences of test dataset for human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee9781be-de73-44ff-b84e-7655ab12f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5720f43a-4ebf-46d3-a2dc-e7c4b3d0e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [18:39<00:00,  1.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "test_input = test_dataset['translation']\n",
    "\n",
    "for input_text in tqdm(test_input):\n",
    "    source_sentence = input_text[CHINESE]\n",
    "    encoded_source = tokenizer(source_sentence,\n",
    "                               return_tensors='pt',\n",
    "                               padding=True,\n",
    "                               truncation=True)\n",
    "    encoded_source.to(device)  # Move input tensor to the same device as the model\n",
    "\n",
    "    translated = model.generate(**encoded_source)\n",
    "\n",
    "    predictions.append([tokenizer.decode(t, skip_special_tokens=True) for t in translated][0])\n",
    "\n",
    "# Move the model back to CPU if needed\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbcb743f-78ae-4597-8279-1acd71348fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 143493.12it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true_en = []\n",
    "y_true_pt = []\n",
    "\n",
    "for input_text in tqdm(test_input):\n",
    "    y_true_pt.append(input_text[CHINESE])\n",
    "    y_true_en.append(input_text[ENGLISH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d2cf24e-413d-4a5a-9937-378a4298636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_port</th>\n",
       "      <th>y_true_eng</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[è¿™äº› ç‰¹æ®Š åˆ©ç›Š åŒ…æ‹¬ åå°”è¡— ã€ å¤§ çŸ³æ²¹ å…¬å¸ ã€ å¤§ äººå¯¿ä¿é™© å•† ä»¥åŠ å†›ç«å•† ã€‚...</td>\n",
       "      <td>[These special interests included Wall Street,...</td>\n",
       "      <td>Such special interests include Wall Street, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ç»è¿‡ å¤šå¹´ çš„ äº‰è®º å’Œ å¸ƒä»€ æ”¿åºœ åå¯¹ é‡‡å–ä»»ä½• è¡ŒåŠ¨ çš„ æ€åº¦ å½±å“ ï¼Œ ç¾å›½ ç»ˆäº...</td>\n",
       "      <td>[After years of debate in the United States, a...</td>\n",
       "      <td>After years of wrangling and the Bush administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[æœ‰ æ•°ç™¾ä¸‡ ä¸œå—äºš äºº å†’é™© åˆ° ä¸­ä¸œ å·¥ä½œ ï¼Œ ä½†æ˜¯ è¿˜æœ‰ æ•°ç™¾ä¸‡ äºº è·¨å¢ƒ åˆ° è¯¥ åœ°...</td>\n",
       "      <td>[Millions of people in Southeast Asia venture ...</td>\n",
       "      <td>Many millions of Southeast Asians risk working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[å€¼å¾—ä¸€æçš„æ˜¯ ä¸‰ä½ å‰ æ‹‰ç¾ æ€»ç»Ÿ ï¼Œ å¢¨è¥¿å“¥ æ’å ç¬¬äºŒ çš„ å¯Œç¿ é‡Œå¡å¤š Â· è¨åˆ©çº³æ–¯...</td>\n",
       "      <td>[Three former Latin American presidents, Mexic...</td>\n",
       "      <td>Mention should be taken of three former Latin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[è‚¥æ–™ å’Œ æ€è™«å‰‚ çš„ ä»·æ ¼ éƒ½ æ¯” æˆ‘ æƒ³è±¡ çš„ è¦ è´µ ã€‚  ]</td>\n",
       "      <td>[Fertilizer and spraying were both more expens...</td>\n",
       "      <td>The price of fertilizer and pesticides is more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[è§£å†³é—®é¢˜ éœ€è¦ å‘¼å å¢åŠ  ç¨æ”¶ ï¼Œ è€Œ ä¹”æ²» Â· W Â· å¸ƒä»€ 1992 å¹´ å¾—åˆ° çš„ ...</td>\n",
       "      <td>[To do so would require calling for higher tax...</td>\n",
       "      <td>Solving the problem requires an increase in ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[ç¾å›½ çš„ æˆ˜ç•¥ çœŸç©º  ]</td>\n",
       "      <td>[Americaâ€™s Strategy Vacuum ]</td>\n",
       "      <td>Americaâ€™s Strategy Gap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[æ ¹æ® å¯¹ 7000 å®¶ å…¬å¸ æ‰€ åš çš„ æœˆåº¦ è°ƒæŸ¥ ï¼Œ Ifo çš„ å¾·å›½ ç»æµ æ™¯æ°” æŒ‡...</td>\n",
       "      <td>[The Ifo climate indicator for Germany, based ...</td>\n",
       "      <td>According to a monthly survey of 700,000 compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[å…¶ä¸€ æ˜¯ ç§»æ°‘ æ”¹é© ï¼Œ è¿™ä¸ª é—®é¢˜ åœ¨ ç¾å›½ ä¸ åœ¨ æ¬§æ´² ä¸€æ · å­˜åœ¨ äº‰è®® ã€‚  ]</td>\n",
       "      <td>[One is immigration reform, which is as contro...</td>\n",
       "      <td>One is immigration reform, a matter that is as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[è¿™ç§ ç‰¹æ€§ ä½¿å¾— è¶…å¯¼ä½“ æ‹¥æœ‰ äº† å¯ä¾› å¤šæ–¹é¢ åˆ©ç”¨ çš„ ç‹¬æœ‰ ç‰¹å¾ ã€‚  ]</td>\n",
       "      <td>[Because of this property, superconductors hav...</td>\n",
       "      <td>Such properties put superconductors in the uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           y_true_port  \\\n",
       "0    [è¿™äº› ç‰¹æ®Š åˆ©ç›Š åŒ…æ‹¬ åå°”è¡— ã€ å¤§ çŸ³æ²¹ å…¬å¸ ã€ å¤§ äººå¯¿ä¿é™© å•† ä»¥åŠ å†›ç«å•† ã€‚...   \n",
       "1    [ç»è¿‡ å¤šå¹´ çš„ äº‰è®º å’Œ å¸ƒä»€ æ”¿åºœ åå¯¹ é‡‡å–ä»»ä½• è¡ŒåŠ¨ çš„ æ€åº¦ å½±å“ ï¼Œ ç¾å›½ ç»ˆäº...   \n",
       "2    [æœ‰ æ•°ç™¾ä¸‡ ä¸œå—äºš äºº å†’é™© åˆ° ä¸­ä¸œ å·¥ä½œ ï¼Œ ä½†æ˜¯ è¿˜æœ‰ æ•°ç™¾ä¸‡ äºº è·¨å¢ƒ åˆ° è¯¥ åœ°...   \n",
       "3    [å€¼å¾—ä¸€æçš„æ˜¯ ä¸‰ä½ å‰ æ‹‰ç¾ æ€»ç»Ÿ ï¼Œ å¢¨è¥¿å“¥ æ’å ç¬¬äºŒ çš„ å¯Œç¿ é‡Œå¡å¤š Â· è¨åˆ©çº³æ–¯...   \n",
       "4                   [è‚¥æ–™ å’Œ æ€è™«å‰‚ çš„ ä»·æ ¼ éƒ½ æ¯” æˆ‘ æƒ³è±¡ çš„ è¦ è´µ ã€‚  ]   \n",
       "..                                                 ...   \n",
       "995  [è§£å†³é—®é¢˜ éœ€è¦ å‘¼å å¢åŠ  ç¨æ”¶ ï¼Œ è€Œ ä¹”æ²» Â· W Â· å¸ƒä»€ 1992 å¹´ å¾—åˆ° çš„ ...   \n",
       "996                                     [ç¾å›½ çš„ æˆ˜ç•¥ çœŸç©º  ]   \n",
       "997  [æ ¹æ® å¯¹ 7000 å®¶ å…¬å¸ æ‰€ åš çš„ æœˆåº¦ è°ƒæŸ¥ ï¼Œ Ifo çš„ å¾·å›½ ç»æµ æ™¯æ°” æŒ‡...   \n",
       "998      [å…¶ä¸€ æ˜¯ ç§»æ°‘ æ”¹é© ï¼Œ è¿™ä¸ª é—®é¢˜ åœ¨ ç¾å›½ ä¸ åœ¨ æ¬§æ´² ä¸€æ · å­˜åœ¨ äº‰è®® ã€‚  ]   \n",
       "999          [è¿™ç§ ç‰¹æ€§ ä½¿å¾— è¶…å¯¼ä½“ æ‹¥æœ‰ äº† å¯ä¾› å¤šæ–¹é¢ åˆ©ç”¨ çš„ ç‹¬æœ‰ ç‰¹å¾ ã€‚  ]   \n",
       "\n",
       "                                            y_true_eng  \\\n",
       "0    [These special interests included Wall Street,...   \n",
       "1    [After years of debate in the United States, a...   \n",
       "2    [Millions of people in Southeast Asia venture ...   \n",
       "3    [Three former Latin American presidents, Mexic...   \n",
       "4    [Fertilizer and spraying were both more expens...   \n",
       "..                                                 ...   \n",
       "995  [To do so would require calling for higher tax...   \n",
       "996                       [Americaâ€™s Strategy Vacuum ]   \n",
       "997  [The Ifo climate indicator for Germany, based ...   \n",
       "998  [One is immigration reform, which is as contro...   \n",
       "999  [Because of this property, superconductors hav...   \n",
       "\n",
       "                                        predicted_text  \n",
       "0    Such special interests include Wall Street, la...  \n",
       "1    After years of wrangling and the Bush administ...  \n",
       "2    Many millions of Southeast Asians risk working...  \n",
       "3    Mention should be taken of three former Latin ...  \n",
       "4    The price of fertilizer and pesticides is more...  \n",
       "..                                                 ...  \n",
       "995  Solving the problem requires an increase in ta...  \n",
       "996                             Americaâ€™s Strategy Gap  \n",
       "997  According to a monthly survey of 700,000 compa...  \n",
       "998  One is immigration reform, a matter that is as...  \n",
       "999  Such properties put superconductors in the uni...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame({\"y_true_port\": y_true_pt, \"y_true_eng\": y_true_en, \"predicted_text\": predictions})\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ace793dc-58a1-4354-9e39-a2ab8c612c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('translation.csv', index=False, encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
